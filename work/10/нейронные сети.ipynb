{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"KBeojQNTzwY-"},"source":["В этом занятии вам предстоит потренироваться построению нейронных сетей с помощью библиотеки Pytorch.\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"Kd-KUTc1CBXm"},"source":["import numpy as np\n","\n","import seaborn as sns\n","from matplotlib import pyplot as plt\n","\n","from sklearn.datasets import make_moons\n","from sklearn.model_selection import train_test_split\n","\n","import torch\n","from torch import nn\n","from torch.nn import functional as F\n","\n","from torch.utils.data import TensorDataset, DataLoader\n","\n","sns.set(style=\"darkgrid\", font_scale=1.4)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HvKrWYan4Rxr"},"source":["# Часть 1. Датасет moons"]},{"cell_type":"code","metadata":{"id":"lo3nwjSJFUP7"},"source":["X, y = make_moons(n_samples=10000, random_state=42, noise=0.1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xa9UCvRyJFqL"},"source":["plt.figure(figsize=(16, 10))\n","plt.title(\"Dataset\")\n","plt.scatter(X[:, 0], X[:, 1], c=y, cmap=\"viridis\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r6BcB14d4wGm"},"source":["Сделаем train/test split"]},{"cell_type":"code","metadata":{"id":"fv5MyTiCHjRh"},"source":["X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=42)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iTeLXQg240cQ"},"source":["### Загрузка данных\n","В PyTorch загрузка данных как правило происходит налету (иногда датасеты не помещаются в оперативную память). Для этого используются две сущности `Dataset` и `DataLoader`.\n","\n","1.   `Dataset` загружает каждый объект по отдельности.\n","\n","2.   `DataLoader` группирует объекты из `Dataset` в батчи.\n","\n","Так как наш датасет достаточно маленький мы будем использовать `TensorDataset`. Все, что нам нужно, это перевести из массива numpy в тензор с типом `torch.float32`.\n","\n","### Задание. Создайте тензоры с обучающими и тестовыми данными"]},{"cell_type":"code","metadata":{"id":"msj3bXOeIcN-"},"source":["X_train_t =  # YOUR CODE GOES HERE\n","y_train_t =  # YOUR CODE GOES HERE\n","X_val_t =  # YOUR CODE GOES HERE\n","y_val_t =  # YOUR CODE GOES HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gqwGMsE_7WBy"},"source":["Создаем `Dataset` и `DataLoader`."]},{"cell_type":"code","metadata":{"id":"ERvubjbMIu2J"},"source":["train_dataset = TensorDataset(X_train_t, y_train_t)\n","val_dataset = TensorDataset(X_val_t, y_val_t)\n","train_dataloader = DataLoader(train_dataset, batch_size=128)\n","val_dataloader = DataLoader(val_dataset, batch_size=128)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BT6eRdVNCO42"},"source":["## Logistic regression\n","\n","**Напоминание**\n","На входе у нас есть матрица объект-признак X и столбец-вектор $y$ – метки из $\\{0, 1\\}$ для каждого объекта. Мы хотим найти такую матрицу весов $W$ и смещение $b$ (bias), что наша модель $XW + b$ будет каким-то образом предсказывать класс объекта. Как видно на выходе наша модель может выдавать число в интервале от $(-\\infty;\\infty)$. Этот выход как правило называют \"логитами\" (logits). Нам необходимо перевести его на интервал от $[0;1]$ для того, чтобы он выдавал нам вероятность принадлежности объекта к кассу один, также лучше, чтобы эта функция была монотонной, быстро считалась, имела производную и на $-\\infty$ имела значение $0$, а на $+\\infty$ имела значение $1$. Такой класс функций называется сигмоидыю. Чаще всего в качестве сигмоида берут\n","$$\n","\\sigma(x) = \\frac{1}{1 + e^{-x}}.\n","$$"]},{"cell_type":"markdown","metadata":{"id":"BKyYQcec7cu4"},"source":["### Задание. Реализация логистической регрессии\n","\n","Вам необходимо написать модуль на PyTorch реализующий $logits = XW + b$, где $W$ и $b$ – параметры (`nn.Parameter`) модели. Иначе говоря, здесь мы реализуем своими руками модуль `nn.Linear` (в этом пункте его использование запрещено). Инициализируйте веса нормальным распределением (`torch.randn`)."]},{"cell_type":"code","metadata":{"id":"5U1y-0KtCTne"},"source":["class LinearRegression(nn.Module):\n","    def __init__(self, in_features: int, out_features: int, bias: bool = True):\n","        super().__init__()\n","        self.weights = nn.Parameter(torch.randn(<YOUR CODE>))\n","        self.bias = bias\n","        if bias:\n","            self.bias_term = # YOUR CODE GOES HERE\n","\n","    def forward(self, x):\n","        x =  # YOUR CODE GOES HERE\n","        if self.bias:\n","            x +=  # YOUR CODE GOES HERE\n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jgIgTLHSM-10"},"source":["linear_regression = LinearRegression(2, 1)\n","loss_function = nn.BCEWithLogitsLoss()\n","optimizer = torch.optim.SGD(linear_regression.parameters(), lr=0.05)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-VCVmee16yOl"},"source":["**Вопрос 1.** Сколько обучаемых параметров у получившейся модели? Имеется в виду суммарное количество отдельных числовых переменных, а не количество тензоров."]},{"cell_type":"code","metadata":{"id":"YbTwo8Zt62Y5"},"source":["#YOUR CODE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4NV-JrNCoP8E"},"source":["### Train loop\n","\n","Вот псевдокод, который поможет вам разобраться в том, что происходит во время обучения\n","\n","```python\n","for epoch in range(max_epochs):  # <----------- итерируемся по датасету несколько раз\n","    for x_batch, y_batch in dataset:  # <------ итерируемся по датасету. Так как мы используем SGD а не GD, то берем батчи заданного размера\n","        optimizer.zero_grad()  # <------------- обуляем градиенты модели\n","        outp = model(x_batch)  # <------------- получаем \"логиты\" из модели\n","        loss = loss_func(outp, y_batch)  # <--- считаем \"лосс\" для логистической регрессии\n","        loss.backward()  # <------------------- считаем градиенты\n","        optimizer.step()  # <------------------ делаем шаг градиентного спуска\n","        if convergence:  # <------------------- в случае сходимости выходим из цикла\n","            break\n","```\n","\n","В коде ниже добавлено логирование `accuracy` и `loss`."]},{"cell_type":"markdown","metadata":{"id":"U1DvfCPY7TMZ"},"source":["### Задание. Реализация цикла обучения"]},{"cell_type":"code","metadata":{"id":"gVhlIfK0L93s"},"source":["tol = 1e-3\n","losses = []\n","max_epochs = 100\n","prev_weights = torch.zeros_like(linear_regression.weights)\n","stop_it = False\n","for epoch in range(max_epochs):\n","    for it, (X_batch, y_batch) in enumerate(train_dataloader):\n","        optimizer.zero_grad()\n","        outp =  # YOUR CODE. Use linear_regression to get outputs\n","        loss =  # YOUR CODE. Compute loss\n","        loss.backward()\n","        losses.append(loss.detach().flatten()[0])\n","        optimizer.step()\n","        probabilities =  # YOUR CODE. Compute probabilities\n","        preds = (probabilities > 0.5).type(torch.long)\n","        batch_acc = (preds.flatten() == y_batch).type(torch.float32).sum() / y_batch.size(0)\n","\n","        if (it + epoch * len(train_dataloader)) % 100 == 0:\n","            print(f\"Iteration: {it + epoch * len(train_dataloader)}\\nBatch accuracy: {batch_acc}\")\n","        current_weights = linear_regression.weights.detach().clone()\n","        if (prev_weights - current_weights).abs().max() < tol:\n","            print(f\"\\nIteration: {it + epoch * len(train_dataloader)}.Convergence. Stopping iterations.\")\n","            stop_it = True\n","            break\n","        prev_weights = current_weights\n","    if stop_it:\n","        break"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"As-pgFbzFmiI"},"source":["### Визуализируем результаты"]},{"cell_type":"code","metadata":{"id":"HzPRB8j4b1IF"},"source":["plt.figure(figsize=(12, 8))\n","plt.plot(range(len(losses)), losses)\n","plt.xlabel(\"Iteration\")\n","plt.ylabel(\"Loss\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9cGgcBMNX2WP"},"source":["import numpy as np\n","\n","sns.set(style=\"white\")\n","\n","xx, yy = np.mgrid[-1.5:2.5:.01, -1.:1.5:.01]\n","grid = np.c_[xx.ravel(), yy.ravel()]\n","batch = torch.from_numpy(grid).type(torch.float32)\n","with torch.no_grad():\n","    probs = torch.sigmoid(linear_regression(batch).reshape(xx.shape))\n","    probs = probs.numpy().reshape(xx.shape)\n","\n","f, ax = plt.subplots(figsize=(16, 10))\n","ax.set_title(\"Decision boundary\", fontsize=14)\n","contour = ax.contourf(xx, yy, probs, 25, cmap=\"RdBu\",\n","                      vmin=0, vmax=1)\n","ax_c = f.colorbar(contour)\n","ax_c.set_label(\"$P(y = 1)$\")\n","ax_c.set_ticks([0, .25, .5, .75, 1])\n","\n","ax.scatter(X[100:,0], X[100:, 1], c=y[100:], s=50,\n","           cmap=\"RdBu\", vmin=-.2, vmax=1.2,\n","           edgecolor=\"white\", linewidth=1)\n","\n","ax.set(xlabel=\"$X_1$\", ylabel=\"$X_2$\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M9G-UkrE-Arr"},"source":["### Задание. Реализуйте predict и посчитайте accuracy на test."]},{"cell_type":"code","metadata":{"id":"FP_imFpe7Ac4"},"source":["@torch.no_grad()\n","def predict(dataloader, model):\n","    model.eval()\n","    predictions = np.array([])\n","    for x_batch, _ in dataloader:\n","        <YOUR CODE>\n","        preds = #YOUR CODE. Compute predictions\n","        predictions = np.hstack((predictions, preds.numpy().flatten()))\n","    return predictions.flatten()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v0vaJdAS7Dfq"},"source":["from sklearn.metrics import accuracy_score\n","\n","# YOUR CODE. Compute total accuracy"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"s7TXs3kk7Kmq"},"source":["**Вопрос 2**\n","\n","Какое `accuracy` получается после обучения?\n","\n","**Ответ:**"]},{"cell_type":"markdown","metadata":{"id":"cyivMZBZC0Ha"},"source":["# Часть 2. Датасет MNIST"]},{"cell_type":"code","metadata":{"id":"LuUE2wihC4GW"},"source":["import os\n","from torchvision.datasets import MNIST\n","from torchvision import transforms as tfs\n","\n","\n","data_tfs = tfs.Compose([\n","    tfs.ToTensor(),\n","    tfs.Normalize((0.5), (0.5))\n","])\n","\n","# install for train and test\n","root = './'\n","train_dataset = MNIST(root, train=True,  transform=data_tfs, download=True)\n","val_dataset  = MNIST(root, train=False, transform=data_tfs, download=True)\n","\n","train_dataloader =  # YOUR CODE GOES HERE\n","valid_dataloader =  # YOUR CODE GOES HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4t2w2XtSB1Hd"},"source":["## Часть 2.1. Полносвязные нейронные сети"]},{"cell_type":"code","metadata":{"id":"Zvcy_wYFh1Lv"},"source":["class Identical(nn.Module):\n","    def forward(self, x):\n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HMtCBdCA-4bj"},"source":["### Задание. Простая полносвязная нейронная сеть\n","\n","Создайте полносвязную нейронную сеть с помощью класса Sequential. Сеть состоит из:\n","* Уплощения матрицы в вектор (nn.Flatten);\n","* Двух скрытых слоёв из 128 нейронов с активацией nn.ELU;\n","* Выходного слоя с 10 нейронами.\n","\n","Задайте лосс для обучения (кросс-энтропия).\n"]},{"cell_type":"code","metadata":{"id":"ulxWHddEiQCr"},"source":["activation = nn.ELU\n","\n","model = nn.Sequential(\n","    nn.Flatten(),\n","    #YOUR CODE. Add layers to your sequential class\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FIl6z-AfivcK"},"source":["criterion = #YOUR CODE. Select a loss function\n","optimizer = torch.optim.Adam(model.parameters())\n","\n","loaders = {\"train\": train_dataloader, \"valid\": valid_dataloader}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"whvqhLjYmpKc"},"source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4Xl_HawRGRAe"},"source":["### Train loop (seriously)\n","\n","\n","\n","```python\n","for epoch in range(max_epochs):  # <--------------- итерируемся по датасету несколько раз\n","    for k, dataloader in loaders.items():  # <----- несколько dataloader для train / valid / test\n","        for x_batch, y_batch in dataloader:  # <--- итерируемся по датасету. Так как мы используем SGD а не GD, то берем батчи заданного размера\n","            if k == \"train\":\n","                model.train()  # <------------------ переводим модель в режим train\n","                optimizer.zero_grad()  # <--------- обнуляем градиенты модели\n","                outp = model(x_batch)\n","                loss = criterion(outp, y_batch) # <-считаем \"лосс\" для логистической регрессии\n","                loss.backward()  # <--------------- считаем градиенты\n","                optimizer.step()  # <-------------- делаем шаг градиентного спуска\n","            else:  # <----------------------------- test/eval\n","                model.eval()  # <------------------ переводим модель в режим eval\n","                with torch.no_grad():  # <--------- НЕ считаем градиенты\n","                    outp = model(x_batch)  # <------------- получаем \"логиты\" из модели\n","            count_metrics(outp, y_batch)  # <-------------- считаем метрики\n","```"]},{"cell_type":"markdown","metadata":{"id":"raKQWwQm_9Ff"},"source":["### Задание. Дополните цикл обучения."]},{"cell_type":"code","metadata":{"id":"3Tmo1lsHjBE6"},"source":["max_epochs = 10\n","accuracy = {\"train\": [], \"valid\": []}\n","for epoch in range(max_epochs):\n","    for k, dataloader in loaders.items():\n","        epoch_correct = 0\n","        epoch_all = 0\n","        for x_batch, y_batch in dataloader:\n","            if k == \"train\":\n","                 # YOUR CODE. Set model to ``train`` mode and calculate outputs. Don't forget zero_grad!\n","            else:\n","                 # YOUR CODE. Set model to ``eval`` mode and calculate outputs\n","            preds = outp.argmax(-1)\n","            correct =  # YOUR CODE GOES HERE\n","            all =  # YOUR CODE GOES HERE\n","            epoch_correct += correct.item()\n","            epoch_all += all\n","            if k == \"train\":\n","                loss = criterion(outp, y_batch)\n","                # YOUR CODE. Calculate gradients and make a step of your optimizer\n","        if k == \"train\":\n","            print(f\"Epoch: {epoch+1}\")\n","        print(f\"Loader: {k}. Accuracy: {epoch_correct/epoch_all}\")\n","        accuracy[k].append(epoch_correct/epoch_all)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fFRxO1-FK9U9"},"source":["### Задание. Протестируйте разные функции активации.\n","Попробуйте разные функции активации. Для каждой функции активации посчитайте массив validation accuracy. Лучше реализовать это в виде функции, берущей на вход активацию и получающей массив из accuracies."]},{"cell_type":"code","metadata":{"id":"SezseDhEqhm2"},"source":["elu_accuracy = accuracy[\"valid\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lSVBlHtuAUAh"},"source":["# YOUR CODE. Do the same thing with other activations (it's better to wrap into a function that returns a list of accuracies)\n","\n","def test_activation_function(activation):\n","    #YOUR CODE"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a1iXow0Tqsri"},"source":["plain_accuracy = test_activation_function(Identical)\n","relu_accuracy = #YOUR CODE\n","leaky_relu_accuracy = #YOUR CODE\n","thang_accuracy = #"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FK07mms3FwNd"},"source":["### Accuracy\n","Построим график accuracy/epoch для каждой функции активации."]},{"cell_type":"code","metadata":{"id":"cvKclpM5r-P3"},"source":["sns.set(style=\"darkgrid\", font_scale=1.4)\n","\n","plt.figure(figsize=(16, 10))\n","plt.title(\"Valid accuracy\")\n","plt.plot(range(max_epochs), plain_accuracy, label=\"No activation\", linewidth=2)\n","plt.plot(range(max_epochs), relu_accuracy, label=\"ReLU activation\", linewidth=2)\n","plt.plot(range(max_epochs), leaky_relu_accuracy, label=\"LeakyReLU activation\", linewidth=2)\n","plt.plot(range(max_epochs), elu_accuracy, label=\"ELU activation\", linewidth=2)\n","plt.legend()\n","plt.xlabel(\"Epoch\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4R8L1JCts_qz"},"source":["plt.figure(figsize=(16, 10))\n","plt.title(\"Valid accuracy\")\n","plt.plot(range(max_epochs), relu_accuracy, label=\"ReLU activation\", linewidth=2)\n","plt.plot(range(max_epochs), leaky_relu_accuracy, label=\"LeakyReLU activation\", linewidth=2)\n","plt.plot(range(max_epochs), elu_accuracy, label=\"ELU activation\", linewidth=2)\n","plt.legend()\n","plt.xlabel(\"Epoch\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bl8qYSSa7c-r"},"source":["**Вопрос 3.** Какая из активаций показала наивысший `accuracy` к концу обучения?\n","\n","**Ответ:**"]}]}