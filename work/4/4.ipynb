{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# задание 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используя датасеты о продуктах и их продажах посчитайте корреляции:\n",
    "* Пирсона\n",
    "* Спирмена\n",
    "* Мэтьюса\n",
    "* Крамера\n",
    "\n",
    "Ход работы:\n",
    "* Прочтите данные о продажах и продуктах\n",
    "* Соедините таблицы друг с другом по id продукта\n",
    "* Посчитайте корреляцию Спирмена временного ряда продаж каждого продукта с каждым, используя соединенную таблицу\n",
    "* Посчитайте корреляцию Пирсона временного ряда продаж каждого продукта с каждым, используя соединенную таблицу\n",
    "* Найдите наиболее коррелирующий товар с American Chicken Hot Dogs по значению корреляции Спирмена и Пиарсона\n",
    "* Постройте график зависимости продаж American Chicken Hot Dogs от найденного товара (scatterplot) и постройте два графика 1) зависимости продаж American Chicken Hot Dogs от времени 2) зависимости продаж найденного товара от времени (lineplot).\n",
    "* Найдите корреляцию Мэтьюса между recyclable_package и low_fat\n",
    "* Постройте гистограммы recyclable_package и low_fat.\n",
    "* Найдите корреляцию Крамера между store_id и brand_name. Есть ли корреляция между этими признаками?\n",
    "* Визуализируйте зависимость store_id и brand_name. Тут подумайте, как это можно сделать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "df_products = pd.read_csv(\"foodmart.products.csv\")\n",
    "df_sales = pd.read_csv(\"foodmart.sales.csv\")\n",
    "\n",
    "df = df_products.merge(df_sales, on=\"product_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product_id      1         2         3         4         5         6     \\\n",
      "product_id                                                               \n",
      "1           1.000000 -0.036463 -0.063465 -0.098678  0.139663  0.069102   \n",
      "2          -0.036463  1.000000 -0.085617  0.009879  0.068889  0.137239   \n",
      "3          -0.063465 -0.085617  1.000000  0.023985  0.016734  0.012570   \n",
      "4          -0.098678  0.009879  0.023985  1.000000 -0.034646  0.024591   \n",
      "5           0.139663  0.068889  0.016734 -0.034646  1.000000 -0.029999   \n",
      "...              ...       ...       ...       ...       ...       ...   \n",
      "1555        0.045023 -0.030692 -0.049421 -0.068105 -0.055464 -0.049138   \n",
      "1556       -0.009169  0.047352  0.015996  0.022375  0.028984 -0.026869   \n",
      "1557        0.047198  0.009504  0.077185 -0.034351  0.050960  0.064718   \n",
      "1558       -0.040305  0.038253  0.047757 -0.027468  0.024547  0.053573   \n",
      "1559       -0.009491 -0.009349 -0.063920  0.007291  0.078572 -0.010639   \n",
      "\n",
      "product_id      7         8         9         10    ...      1550      1551  \\\n",
      "product_id                                          ...                       \n",
      "1          -0.006522  0.094662  0.076706 -0.062877  ... -0.053629  0.065790   \n",
      "2          -0.012006  0.043265  0.007982  0.009164  ... -0.036295 -0.007800   \n",
      "3          -0.029500 -0.007450  0.082136 -0.044088  ...  0.023751 -0.003355   \n",
      "4           0.007050  0.027666  0.010916 -0.034035  ... -0.101600 -0.045616   \n",
      "5          -0.031423  0.008138 -0.011080 -0.005913  ... -0.019443 -0.008324   \n",
      "...              ...       ...       ...       ...  ...       ...       ...   \n",
      "1555       -0.031586  0.029492  0.007859  0.162543  ...  0.002645 -0.079594   \n",
      "1556        0.026927  0.027761 -0.108870  0.032724  ... -0.019489  0.062807   \n",
      "1557        0.050037  0.068753  0.080330 -0.025630  ... -0.040151  0.070749   \n",
      "1558       -0.018348  0.052326  0.043729  0.024983  ...  0.102130 -0.012275   \n",
      "1559        0.089723  0.120307 -0.099165  0.048871  ...  0.003552 -0.041275   \n",
      "\n",
      "product_id      1552      1553      1554      1555      1556      1557  \\\n",
      "product_id                                                               \n",
      "1           0.074063  0.019647  0.020062  0.045023 -0.009169  0.047198   \n",
      "2           0.052551 -0.023106 -0.003272 -0.030692  0.047352  0.009504   \n",
      "3          -0.068391  0.035395 -0.019956 -0.049421  0.015996  0.077185   \n",
      "4          -0.049871 -0.036638 -0.018577 -0.068105  0.022375 -0.034351   \n",
      "5          -0.051702  0.138909  0.086818 -0.055464  0.028984  0.050960   \n",
      "...              ...       ...       ...       ...       ...       ...   \n",
      "1555       -0.030700 -0.010403 -0.069236  1.000000  0.007257 -0.101044   \n",
      "1556        0.083067  0.104087 -0.002789  0.007257  1.000000 -0.004981   \n",
      "1557       -0.146589  0.087899  0.134807 -0.101044 -0.004981  1.000000   \n",
      "1558        0.006126 -0.146969  0.079669  0.036150  0.000412 -0.084852   \n",
      "1559        0.018779  0.103391  0.071757  0.040677 -0.010422 -0.142849   \n",
      "\n",
      "product_id      1558      1559  \n",
      "product_id                      \n",
      "1          -0.040305 -0.009491  \n",
      "2           0.038253 -0.009349  \n",
      "3           0.047757 -0.063920  \n",
      "4          -0.027468  0.007291  \n",
      "5           0.024547  0.078572  \n",
      "...              ...       ...  \n",
      "1555        0.036150  0.040677  \n",
      "1556        0.000412 -0.010422  \n",
      "1557       -0.084852 -0.142849  \n",
      "1558        1.000000  0.063955  \n",
      "1559        0.063955  1.000000  \n",
      "\n",
      "[1559 rows x 1559 columns]\n"
     ]
    }
   ],
   "source": [
    "df['unique_id'] = df.groupby(['date', 'product_id']).cumcount()\n",
    "\n",
    "pivot_df = df.pivot(index=[\"date\", \"unique_id\"], columns=\"product_id\", values=\"sales\")\n",
    "\n",
    "pivot_df = pivot_df.fillna(pivot_df.mean())\n",
    "\n",
    "spearman_corr_matrix = pivot_df.corr(method='spearman')\n",
    "\n",
    "print(spearman_corr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product_id      1         2         3         4         5         6     \\\n",
      "product_id                                                               \n",
      "1           1.000000 -0.074340  0.003027 -0.026165  0.012192 -0.011795   \n",
      "2          -0.074340  1.000000 -0.100067  0.048536 -0.048278 -0.029873   \n",
      "3           0.003027 -0.100067  1.000000  0.014118  0.046425 -0.009659   \n",
      "4          -0.026165  0.048536  0.014118  1.000000 -0.023893 -0.021474   \n",
      "5           0.012192 -0.048278  0.046425 -0.023893  1.000000 -0.031838   \n",
      "...              ...       ...       ...       ...       ...       ...   \n",
      "1555        0.009620 -0.021286 -0.074559 -0.004505 -0.002984 -0.059361   \n",
      "1556        0.002204  0.074762  0.042186 -0.004819  0.047018 -0.028426   \n",
      "1557       -0.006241 -0.018018 -0.003468 -0.029400 -0.045373  0.067679   \n",
      "1558       -0.014021  0.034532  0.352991 -0.049270 -0.031070  0.036152   \n",
      "1559        0.027689  0.061250 -0.035529  0.001564  0.029950 -0.119402   \n",
      "\n",
      "product_id      7         8         9         10    ...      1550      1551  \\\n",
      "product_id                                          ...                       \n",
      "1          -0.005903  0.093362  0.120612 -0.053498  ... -0.037324  0.017586   \n",
      "2          -0.031226  0.030291 -0.001218 -0.014955  ... -0.004497  0.003397   \n",
      "3          -0.083825 -0.034294  0.033538 -0.010294  ...  0.010022  0.280219   \n",
      "4          -0.011247  0.125201 -0.011566  0.045687  ... -0.048597 -0.018755   \n",
      "5          -0.066575  0.026573 -0.001712  0.031258  ... -0.026694 -0.007658   \n",
      "...              ...       ...       ...       ...  ...       ...       ...   \n",
      "1555       -0.036787  0.035790 -0.075473  0.093406  ... -0.012263 -0.020756   \n",
      "1556       -0.044771 -0.005580 -0.037460  0.018424  ... -0.120684  0.000717   \n",
      "1557        0.074924  0.134440  0.064205 -0.012859  ... -0.069085  0.013783   \n",
      "1558       -0.138872 -0.034344  0.001547 -0.061581  ...  0.093214  0.411579   \n",
      "1559       -0.022083  0.078569 -0.058287  0.071511  ...  0.014117 -0.014682   \n",
      "\n",
      "product_id      1552      1553      1554      1555          1556      1557  \\\n",
      "product_id                                                                   \n",
      "1           0.007530 -0.020572  0.016945  0.009620  2.204307e-03 -0.006241   \n",
      "2           0.014182  0.019966 -0.008746 -0.021286  7.476220e-02 -0.018018   \n",
      "3          -0.222283  0.051504 -0.020995 -0.074559  4.218615e-02 -0.003468   \n",
      "4           0.011086 -0.110530 -0.027254 -0.004505 -4.819455e-03 -0.029400   \n",
      "5          -0.041192  0.041386 -0.001221 -0.002984  4.701784e-02 -0.045373   \n",
      "...              ...       ...       ...       ...           ...       ...   \n",
      "1555        0.039711  0.005081 -0.044218  1.000000  2.235188e-02 -0.026652   \n",
      "1556       -0.002761  0.085732 -0.045823  0.022352  1.000000e+00  0.042853   \n",
      "1557       -0.167611  0.146576  0.031478 -0.026652  4.285288e-02  1.000000   \n",
      "1558       -0.163561 -0.053064 -0.000153  0.067071 -6.675392e-02  0.001407   \n",
      "1559       -0.006775  0.060359  0.071956  0.023032 -2.541266e-17 -0.058135   \n",
      "\n",
      "product_id      1558          1559  \n",
      "product_id                          \n",
      "1          -0.014021  2.768878e-02  \n",
      "2           0.034532  6.125024e-02  \n",
      "3           0.352991 -3.552851e-02  \n",
      "4          -0.049270  1.563823e-03  \n",
      "5          -0.031070  2.994989e-02  \n",
      "...              ...           ...  \n",
      "1555        0.067071  2.303166e-02  \n",
      "1556       -0.066754 -2.541266e-17  \n",
      "1557        0.001407 -5.813512e-02  \n",
      "1558        1.000000 -2.134513e-02  \n",
      "1559       -0.021345  1.000000e+00  \n",
      "\n",
      "[1559 rows x 1559 columns]\n"
     ]
    }
   ],
   "source": [
    "pearson_corr_matrix = pivot_df.corr(method='pearson')\n",
    "\n",
    "print(pearson_corr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1462 Hermanos Tangerines\n",
      "668 Gorilla Jack Cheese\n"
     ]
    }
   ],
   "source": [
    "target_id = df[df[\"product_name\"] == \"American Chicken Hot Dogs\"].iloc[0][\"product_id\"]\n",
    "\n",
    "spearman_most_corr_to_target = spearman_corr_matrix[target_id].drop(target_id).idxmax()\n",
    "pearson_most_corr_to_target = pearson_corr_matrix[target_id].drop(target_id).idxmax()\n",
    "\n",
    "print(spearman_most_corr_to_target, df[df[\"product_id\"] == spearman_most_corr_to_target].iloc[0][\"product_name\"])\n",
    "print(pearson_most_corr_to_target, df[df[\"product_id\"] == pearson_most_corr_to_target].iloc[0][\"product_name\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# задание 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## описание задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом задании необходимо достичь максимального качества предсказания, используя навыки полученные за 4 недели обучения\n",
    "\n",
    "Кто достигнет максимального значения на тестовой выборке, получит *15 баллов*\n",
    "\n",
    "Пожалуйста, оформляйте ноутбук аккуратно. Все выводы подписывайте, оформляйте заголовки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для справедливой оценки все должны использовать одну и ту же часть исходного датасета в качестве тестового набора данных. Используйте разбиение приведенное ниже\n",
    "\n",
    "\n",
    "```\n",
    "train_test_split(X, y, test_size = 0.3, random_state = 69, stratify = y)\n",
    "```\n",
    "И модель, с которой вы работаете - это линейнаяэ регрессия. Другие алгоритмы не используйте.\n",
    "\n",
    "Метрика, которую вы должны максимизировать\n",
    "\n",
    "```\n",
    "f1_score(y_test, y_pred, average='weighted')\n",
    "```\n",
    "\n",
    "Целевая переменная - *count*\n",
    "\n",
    "Обратите внимание на столбцы - 'casual', 'registered'. Эти столбцы в сумме дают целевую переменную, по этой причине их надо удалить. Они линейно зависимы.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используйтие средства библиотеки sklearn, внимательно изучите ее. Существует огромное количество методов для выполнения каждого из этапов, не бойтесь использовать методы неприведенные в лекции"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этапы, которые необходимо проделать в работе для успешного достижения результата:\n",
    "* EDA (Исследовать данные, понять с чем имеете дело, наработать идеи для генерации фичей и их обработки, обязательно корреляционные матрицы и графики с hue=классы объектов)\n",
    "* Анализ выбросов и их обработка (в задачах классификации выброс - это объект с таким признаковым описанием, которое отличается очень сильно от типичного и больше соответствует другому классу)\n",
    "* Генерация новых фичей (думайте нетривиально, даю подсказку одной фичи - обратитесь к библиотеке holidays)\n",
    "* Обработка пропусков (вы можете сгенерировать новые фичи с пропусками, тогда надо подумать об их обработке)\n",
    "* Обработка категориальных признаков\n",
    "* Масштабирование вещественных признаков\n",
    "* Трансформирование таргета (необязательно; метрику нужно считать не с измененным таргетом)\n",
    "* Балансировка классов\n",
    "* Нелинейные автоматические трансформации признаков (Kernel Trick, Transformers)\n",
    "* Подбор параметров модели (можете менять не только константы, но и оптимизационные алгоритмы и методы регуляризации)\n",
    "* Отбор признаков\n",
    "* Составление пайплайна обучения\n",
    "* Обязательно: Постройте график зависимости y_pred от y_true в разбиении на test и train. Предсказание идеального алгоритма даст прямую y=x, посмотрите какой график получается у вас."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bike Sharing Demand\n",
    "\n",
    "По историческим данным о прокате велосипедов и погодным условиям необходимо оценить спрос на прокат велосипедов.\n",
    "\n",
    "В наборе признаков присутсвуют вещественные, категориальные, и бинарные данные."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\n",
    "    \"/content/drive/MyDrive/Занятия. Осенний семестр/Домашние работы/Лекция 4. Отбор признаков и пайплайн обучения/bike_sharing_demand.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***datetime*** - hourly date + timestamp  \n",
    "\n",
    "***season*** -  1 = spring, 2 = summer, 3 = fall, 4 = winter\n",
    "\n",
    "***holiday*** - whether the day is considered a holiday\n",
    "\n",
    "***workingday*** - whether the day is neither a weekend nor holiday\n",
    "\n",
    "***weather*** - 1: Clear, Few clouds, Partly cloudy, Partly cloudy\n",
    "2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\n",
    "3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\n",
    "4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog\n",
    "    \n",
    "***temp*** - temperature in Celsius\n",
    "\n",
    "***atemp*** - \"feels like\" temperature in Celsius\n",
    "\n",
    "***humidity*** - relative humidity\n",
    "\n",
    "***windspeed*** - wind speed\n",
    "\n",
    "***casual*** - number of non-registered user rentals initiated\n",
    "\n",
    "***registered*** - number of registered user rentals initiated\n",
    "\n",
    "***count*** - number of total rentals"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
